{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problems and Solution.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya0811/-100daysofMLcode/blob/master/Problems_and_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "or_W6vMzyztX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[Exploding Gradients and ways to counter them](https://machinelearningmastery.com/how-to-avoid-exploding-gradients-in-neural-networks-with-gradient-clipping/)\n",
        "It is possible for the updates to the weights to be so large that the weights either overflow or underflow their numerical precision. In practice, the weights can take on the value of an “NaN” or “Inf” when they overflow or underflow and for practical purposes the network will be useless \n",
        "\n",
        "**Reason**\n",
        "\n",
        "*   Poor choice of learning rate that results in large weight updates.\n",
        "*   Poor choice of data preparation, allowing large differences in the target variable.\n",
        "*   Poor choice of loss function, allowing the calculation of large error values.\n",
        "*   List item\n",
        "\n",
        "**To counter them**\n",
        "\n",
        "\n",
        "*   Gradient Scaling\n",
        "*   Gradient clipping"
      ]
    },
    {
      "metadata": {
        "id": "FSb86hPC0ioF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Gradient Norm Scaling**\n",
        "\n",
        "For example, we could specify a norm of 1.0, meaning that if the vector norm for a gradient exceeds 1.0, then the values in the vector will be rescaled so that the norm of the vector equals 1.0.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vJRu_y6S01tl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Gradient Value Clipping**\n",
        "\n",
        "For example, we could specify a norm of 0.5, meaning that if a gradient value was less than -0.5, it is set to -0.5 and if it is more than 0.5, then it will be set to 0.5."
      ]
    },
    {
      "metadata": {
        "id": "0vGoFEOUxeRb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
